{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos los datos\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corregimos algunos nulos del set de train\n",
    "\n",
    "train_data['keyword'].fillna('no keyword', inplace = True) \n",
    "train_data['keyword'] = train_data['keyword'].str.replace('%20', ' ')\n",
    "train_data['location'].fillna('no location', inplace = True)\n",
    "train_data.drop(['id'],1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corregimos algunos nulos del set de test\n",
    "test_data['keyword'].fillna('no keyword', inplace = True)\n",
    "test_data['keyword'] = train_data['keyword'].str.replace('%20', ' ')\n",
    "test_data['location'].fillna('no location', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIONES UTILES\n",
    "\n",
    "def only_letters(tweet):\n",
    "    tweet = re.sub(r'http\\S*', '', tweet)\n",
    "    tweet = re.sub(r'[^a-z\\s]', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "\n",
    "def filter_stopwords(tokenized_text):\n",
    "    filtered_words=[]\n",
    "    for w in tokenized_text:\n",
    "        if w not in stop_words:\n",
    "            filtered_words.append(w)\n",
    "    return filtered_words\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tweet(tweet):\n",
    "    lemmatized_words = []\n",
    "    for word in tweet:\n",
    "        lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_words\n",
    "\n",
    "def transform_to_text(tweet_words):\n",
    "    return \" \".join(tweet_words)\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer()\n",
    "\n",
    "def process_content(sentence):\n",
    "    tokenized = custom_sent_tokenizer.tokenize(sentence)\n",
    "    words_tagged = []\n",
    "    for i in tokenized:\n",
    "        words = nltk.word_tokenize(i)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        for word in tagged:\n",
    "            words_tagged.append(word)\n",
    "            \n",
    "    return words_tagged\n",
    "\n",
    "#Cleaning text\n",
    "\n",
    "train_data['clean_text'] = train_data['text'].str.lower()\n",
    "test_data['clean_text'] = test_data['text'].str.lower()\n",
    "\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(only_letters)    \n",
    "test_data['clean_text'] = test_data['clean_text'].apply(only_letters)   \n",
    "\n",
    "#Tokenizaci√≥n\n",
    "\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(word_tokenize)\n",
    "test_data['clean_text'] = test_data['clean_text'].apply(word_tokenize)\n",
    "\n",
    "#Remove stopwords\n",
    "\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(filter_stopwords) \n",
    "test_data['clean_text'] = test_data['clean_text'].apply(filter_stopwords)\n",
    "\n",
    "#Lemmatization                                                                       \n",
    "\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(lemmatize_tweet)\n",
    "test_data['clean_text'] = test_data['clean_text'].apply(lemmatize_tweet)\n",
    "\n",
    "#Transform to text\n",
    "train_data['clean_text'] = train_data['clean_text'].apply(transform_to_text)\n",
    "test_data['clean_text'] = test_data['clean_text'].apply(transform_to_text)\n",
    "\n",
    "#Part of speech tagging\n",
    "\n",
    "train_data['tagged_text']= train_data['text'].apply(process_content)\n",
    "train_data['tagged_clean_text']= train_data['clean_text'].apply(process_content)\n",
    "\n",
    "test_data['tagged_text']= test_data['text'].apply(process_content)\n",
    "test_data['tagged_clean_text']= test_data['clean_text'].apply(process_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_Nouns(list):\n",
    "    nouns = 0\n",
    "    for word,tag in list:\n",
    "        if tag[0] == 'N':\n",
    "            nouns += 1\n",
    "        else:\n",
    "            continue\n",
    "    return nouns\n",
    "\n",
    "def count_Adjetives(list):\n",
    "    adjetives = 0\n",
    "    for word,tag in list:\n",
    "        if tag[0] == 'J':\n",
    "            adjetives += 1\n",
    "        else:\n",
    "            continue\n",
    "    return adjetives\n",
    "\n",
    "def count_Verbs(list):\n",
    "    verbs = 0\n",
    "    for word,tag in list:\n",
    "        if tag[0] == 'V':\n",
    "            verbs += 1\n",
    "        else:\n",
    "            continue\n",
    "    return verbs \n",
    "\n",
    "\n",
    "# word_count\n",
    "train_data['word_count'] = train_data['text'].apply(lambda x: len(str(x).split()))\n",
    "test_data['word_count'] = test_data['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# unique_word_count\n",
    "train_data['unique_word_count'] = train_data['text'].apply(lambda x: len(set(str(x).split())))\n",
    "test_data['unique_word_count'] = test_data['text'].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "# stop_word_count\n",
    "train_data['stop_word_count'] = train_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "test_data['stop_word_count'] = test_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if w in stop_words]))\n",
    "\n",
    "# url_count\n",
    "train_data['url_count'] = train_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "test_data['url_count'] = test_data['text'].apply(lambda x: len([w for w in str(x).lower().split() if 'http' in w or 'https' in w]))\n",
    "\n",
    "# mean_word_length\n",
    "train_data['mean_word_length'] = train_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_data['mean_word_length'] = test_data['text'].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# length\n",
    "train_data['tweet_length'] = train_data['text'].apply(lambda x: len(str(x)))\n",
    "test_data['tweet_length'] = test_data['text'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# punctuation_count\n",
    "train_data['punctuation_count'] = train_data['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "test_data['punctuation_count'] = test_data['text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))\n",
    "\n",
    "# hashtag_count\n",
    "train_data['hashtag_count'] = train_data['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "test_data['hashtag_count'] = test_data['text'].apply(lambda x: len([c for c in str(x) if c == '#']))\n",
    "\n",
    "# mention_count\n",
    "train_data['mention_count'] = train_data['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "test_data['mention_count'] = test_data['text'].apply(lambda x: len([c for c in str(x) if c == '@']))\n",
    "\n",
    "#noun_count\n",
    "train_data['noun_count'] = train_data['tagged_text'].apply(count_Nouns)\n",
    "test_data['noun_count'] = test_data['tagged_text'].apply(count_Nouns)\n",
    "\n",
    "#verb_count\n",
    "train_data['verb_count'] = train_data['tagged_text'].apply(count_Verbs)\n",
    "test_data['verb_count'] = test_data['tagged_text'].apply(count_Verbs)\n",
    "\n",
    "#adjetives_count\n",
    "train_data['adjetives_count'] = train_data['tagged_text'].apply(count_Adjetives)\n",
    "test_data['adjetives_count'] = test_data['tagged_text'].apply(count_Adjetives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tagged_text</th>\n",
       "      <th>tagged_clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adjetives_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>[(Our, PRP$), (Deeds, NNS), (are, VBP), (the, ...</td>\n",
       "      <td>[(deed, NN), (reason, NN), (earthquake, NN), (...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[(Forest, NNP), (fire, NN), (near, IN), (La, N...</td>\n",
       "      <td>[(forest, JJS), (fire, NN), (near, IN), (la, J...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>[(All, DT), (residents, NNS), (asked, VBD), (t...</td>\n",
       "      <td>[(resident, NN), (asked, VBD), (shelter, JJ), ...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>[(13,000, CD), (people, NNS), (receive, JJ), (...</td>\n",
       "      <td>[(people, NNS), (receive, VBP), (wildfire, NN)...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[(Just, RB), (got, VBN), (sent, VBD), (this, D...</td>\n",
       "      <td>[(got, VBD), (sent, JJ), (photo, NN), (ruby, N...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      keyword     location                                               text  \\\n",
       "0  no keyword  no location  Our Deeds are the Reason of this #earthquake M...   \n",
       "1  no keyword  no location             Forest fire near La Ronge Sask. Canada   \n",
       "2  no keyword  no location  All residents asked to 'shelter in place' are ...   \n",
       "3  no keyword  no location  13,000 people receive #wildfires evacuation or...   \n",
       "4  no keyword  no location  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         clean_text  \\\n",
       "0       1         deed reason earthquake may allah forgive u   \n",
       "1       1              forest fire near la ronge sask canada   \n",
       "2       1  resident asked shelter place notified officer ...   \n",
       "3       1  people receive wildfire evacuation order calif...   \n",
       "4       1  got sent photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                         tagged_text  \\\n",
       "0  [(Our, PRP$), (Deeds, NNS), (are, VBP), (the, ...   \n",
       "1  [(Forest, NNP), (fire, NN), (near, IN), (La, N...   \n",
       "2  [(All, DT), (residents, NNS), (asked, VBD), (t...   \n",
       "3  [(13,000, CD), (people, NNS), (receive, JJ), (...   \n",
       "4  [(Just, RB), (got, VBN), (sent, VBD), (this, D...   \n",
       "\n",
       "                                   tagged_clean_text  word_count  \\\n",
       "0  [(deed, NN), (reason, NN), (earthquake, NN), (...          13   \n",
       "1  [(forest, JJS), (fire, NN), (near, IN), (la, J...           7   \n",
       "2  [(resident, NN), (asked, VBD), (shelter, JJ), ...          22   \n",
       "3  [(people, NNS), (receive, VBP), (wildfire, NN)...           8   \n",
       "4  [(got, VBD), (sent, JJ), (photo, NN), (ruby, N...          16   \n",
       "\n",
       "   unique_word_count  stop_word_count  url_count  mean_word_length  \\\n",
       "0                 13                6          0          4.384615   \n",
       "1                  7                0          0          4.571429   \n",
       "2                 20               11          0          5.090909   \n",
       "3                  8                1          0          7.125000   \n",
       "4                 15                7          0          4.500000   \n",
       "\n",
       "   tweet_length  punctuation_count  hashtag_count  mention_count  noun_count  \\\n",
       "0            69                  1              1              0           6   \n",
       "1            38                  1              0              0           6   \n",
       "2           133                  3              0              0           7   \n",
       "3            65                  2              1              0           4   \n",
       "4            88                  2              2              0           6   \n",
       "\n",
       "   verb_count  adjetives_count  \n",
       "0           1                0  \n",
       "1           0                0  \n",
       "2           7                1  \n",
       "3           1                1  \n",
       "4           3                0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tagged_text</th>\n",
       "      <th>tagged_clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adjetives_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>[(Just, RB), (happened, VBD), (a, DT), (terrib...</td>\n",
       "      <td>[(happened, VBN), (terrible, JJ), (car, NN), (...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td>[(Heard, NNP), (about, IN), (#, #), (earthquak...</td>\n",
       "      <td>[(heard, RB), (earthquake, NN), (different, JJ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td>[(there, EX), (is, VBZ), (a, DT), (forest, JJ)...</td>\n",
       "      <td>[(forest, JJS), (fire, NN), (spot, NN), (pond,...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>4.105263</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[(Apocalypse, NNP), (lighting, NN), (., .), (#...</td>\n",
       "      <td>[(apocalypse, NN), (lighting, VBG), (spokane, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[(Typhoon, NNP), (Soudelor, NNP), (kills, VBZ)...</td>\n",
       "      <td>[(typhoon, NN), (soudelor, NN), (kill, VB), (c...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword     location  \\\n",
       "0   0  no keyword  no location   \n",
       "1   2  no keyword  no location   \n",
       "2   3  no keyword  no location   \n",
       "3   9  no keyword  no location   \n",
       "4  11  no keyword  no location   \n",
       "\n",
       "                                                text  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Heard about #earthquake is different cities, s...   \n",
       "2  there is a forest fire at spot pond, geese are...   \n",
       "3           Apocalypse lighting. #Spokane #wildfires   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                        happened terrible car crash   \n",
       "1  heard earthquake different city stay safe ever...   \n",
       "2  forest fire spot pond goose fleeing across str...   \n",
       "3               apocalypse lighting spokane wildfire   \n",
       "4                 typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                         tagged_text  \\\n",
       "0  [(Just, RB), (happened, VBD), (a, DT), (terrib...   \n",
       "1  [(Heard, NNP), (about, IN), (#, #), (earthquak...   \n",
       "2  [(there, EX), (is, VBZ), (a, DT), (forest, JJ)...   \n",
       "3  [(Apocalypse, NNP), (lighting, NN), (., .), (#...   \n",
       "4  [(Typhoon, NNP), (Soudelor, NNP), (kills, VBZ)...   \n",
       "\n",
       "                                   tagged_clean_text  word_count  \\\n",
       "0  [(happened, VBN), (terrible, JJ), (car, NN), (...           6   \n",
       "1  [(heard, RB), (earthquake, NN), (different, JJ...           9   \n",
       "2  [(forest, JJS), (fire, NN), (spot, NN), (pond,...          19   \n",
       "3  [(apocalypse, NN), (lighting, VBG), (spokane, ...           4   \n",
       "4  [(typhoon, NN), (soudelor, NN), (kill, VB), (c...           8   \n",
       "\n",
       "   unique_word_count  stop_word_count  url_count  mean_word_length  \\\n",
       "0                  6                2          0          4.833333   \n",
       "1                  9                2          0          6.222222   \n",
       "2                 19                9          0          4.105263   \n",
       "3                  4                0          0          9.250000   \n",
       "4                  8                2          0          4.750000   \n",
       "\n",
       "   tweet_length  punctuation_count  hashtag_count  mention_count  noun_count  \\\n",
       "0            34                  0              0              0           2   \n",
       "1            64                  3              1              0           4   \n",
       "2            96                  2              0              0           4   \n",
       "3            40                  3              2              0           4   \n",
       "4            45                  0              0              0           4   \n",
       "\n",
       "   verb_count  adjetives_count  \n",
       "0           1                1  \n",
       "1           2                2  \n",
       "2           4                2  \n",
       "3           0                0  \n",
       "4           1                0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>aba woman</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoned aircraft</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipper bag</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie apocalypse</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone coming</th>\n",
       "      <th>zone dont</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zouma flattened</th>\n",
       "      <th>_target_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 10913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   aa   ab  aba  aba woman  abandon  abandoned  abandoned aircraft  \\\n",
       "0      0  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "1      1  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "2      2  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "3      3  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "4      4  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "\n",
       "   abbott  abbswinston  ...  zipper  zipper bag  zombie  zombie apocalypse  \\\n",
       "0     0.0          0.0  ...     0.0         0.0     0.0                0.0   \n",
       "1     0.0          0.0  ...     0.0         0.0     0.0                0.0   \n",
       "2     0.0          0.0  ...     0.0         0.0     0.0                0.0   \n",
       "3     0.0          0.0  ...     0.0         0.0     0.0                0.0   \n",
       "4     0.0          0.0  ...     0.0         0.0     0.0                0.0   \n",
       "\n",
       "   zone  zone coming  zone dont  zouma  zouma flattened  _target_  \n",
       "0   0.0          0.0        0.0    0.0              0.0         1  \n",
       "1   0.0          0.0        0.0    0.0              0.0         1  \n",
       "2   0.0          0.0        0.0    0.0              0.0         1  \n",
       "3   0.0          0.0        0.0    0.0              0.0         1  \n",
       "4   0.0          0.0        0.0    0.0              0.0         1  \n",
       "\n",
       "[5 rows x 10913 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf = TfidfVectorizer(min_df = 2, max_df = 0.5, ngram_range= (1,2))\n",
    "\n",
    "#Corremos el algoritmo para TRAIN set \n",
    "texts = train_data['clean_text']\n",
    "features = tf_idf.fit_transform(texts)\n",
    "feature_words = tf_idf.get_feature_names()\n",
    "df_tf_idf = pd.DataFrame(data = features.todense(), columns = tf_idf.get_feature_names())\n",
    "df_tf_idf.shape\n",
    "\n",
    "df_tf_idf[\"_target_\"] = train_data.target\n",
    "df_tf_idf = df_tf_idf.reset_index()\n",
    "df_tf_idf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>aa</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>aba woman</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoned aircraft</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>...</th>\n",
       "      <th>zippednews</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipper bag</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie apocalypse</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone coming</th>\n",
       "      <th>zone dont</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zouma flattened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 10912 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   aa   ab  aba  aba woman  abandon  abandoned  abandoned aircraft  \\\n",
       "0      0  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "1      1  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "2      2  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "3      3  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "4      4  0.0  0.0  0.0        0.0      0.0        0.0                 0.0   \n",
       "\n",
       "   abbott  abbswinston  ...  zippednews  zipper  zipper bag  zombie  \\\n",
       "0     0.0          0.0  ...         0.0     0.0         0.0     0.0   \n",
       "1     0.0          0.0  ...         0.0     0.0         0.0     0.0   \n",
       "2     0.0          0.0  ...         0.0     0.0         0.0     0.0   \n",
       "3     0.0          0.0  ...         0.0     0.0         0.0     0.0   \n",
       "4     0.0          0.0  ...         0.0     0.0         0.0     0.0   \n",
       "\n",
       "   zombie apocalypse  zone  zone coming  zone dont  zouma  zouma flattened  \n",
       "0                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "1                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "2                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "3                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "4                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "\n",
       "[5 rows x 10912 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Corremos el algoritmo para TEST set \n",
    "texts_test = test_data['clean_text']\n",
    "\n",
    "features_test = tf_idf.transform(texts_test)\n",
    "\n",
    "feature_words_test = tf_idf.get_feature_names()\n",
    "\n",
    "df_tf_idf_test = pd.DataFrame(data = features_test.todense(), columns = tf_idf.get_feature_names())\n",
    "df_tf_idf_test.shape\n",
    "\n",
    "df_tf_idf_test = df_tf_idf_test.reset_index()\n",
    "df_tf_idf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>target_x</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tagged_text</th>\n",
       "      <th>tagged_clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipper bag</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie apocalypse</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone coming</th>\n",
       "      <th>zone dont</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zouma flattened</th>\n",
       "      <th>_target_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "      <td>[(Our, PRP$), (Deeds, NNS), (are, VBP), (the, ...</td>\n",
       "      <td>[(deed, NN), (reason, NN), (earthquake, NN), (...</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[(Forest, NNP), (fire, NN), (near, IN), (La, N...</td>\n",
       "      <td>[(forest, JJS), (fire, NN), (near, IN), (la, J...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident asked shelter place notified officer ...</td>\n",
       "      <td>[(All, DT), (residents, NNS), (asked, VBD), (t...</td>\n",
       "      <td>[(resident, NN), (asked, VBD), (shelter, JJ), ...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order calif...</td>\n",
       "      <td>[(13,000, CD), (people, NNS), (receive, JJ), (...</td>\n",
       "      <td>[(people, NNS), (receive, VBP), (wildfire, NN)...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[(Just, RB), (got, VBN), (sent, VBD), (this, D...</td>\n",
       "      <td>[(got, VBD), (sent, JJ), (photo, NN), (ruby, N...</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 10932 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     keyword   location_x  \\\n",
       "0      0  no keyword  no location   \n",
       "1      1  no keyword  no location   \n",
       "2      2  no keyword  no location   \n",
       "3      3  no keyword  no location   \n",
       "4      4  no keyword  no location   \n",
       "\n",
       "                                              text_x  target_x  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...         1   \n",
       "1             Forest fire near La Ronge Sask. Canada         1   \n",
       "2  All residents asked to 'shelter in place' are ...         1   \n",
       "3  13,000 people receive #wildfires evacuation or...         1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...         1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0         deed reason earthquake may allah forgive u   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident asked shelter place notified officer ...   \n",
       "3  people receive wildfire evacuation order calif...   \n",
       "4  got sent photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                         tagged_text  \\\n",
       "0  [(Our, PRP$), (Deeds, NNS), (are, VBP), (the, ...   \n",
       "1  [(Forest, NNP), (fire, NN), (near, IN), (La, N...   \n",
       "2  [(All, DT), (residents, NNS), (asked, VBD), (t...   \n",
       "3  [(13,000, CD), (people, NNS), (receive, JJ), (...   \n",
       "4  [(Just, RB), (got, VBN), (sent, VBD), (this, D...   \n",
       "\n",
       "                                   tagged_clean_text  word_count  \\\n",
       "0  [(deed, NN), (reason, NN), (earthquake, NN), (...          13   \n",
       "1  [(forest, JJS), (fire, NN), (near, IN), (la, J...           7   \n",
       "2  [(resident, NN), (asked, VBD), (shelter, JJ), ...          22   \n",
       "3  [(people, NNS), (receive, VBP), (wildfire, NN)...           8   \n",
       "4  [(got, VBD), (sent, JJ), (photo, NN), (ruby, N...          16   \n",
       "\n",
       "   unique_word_count  ...  zipper  zipper bag  zombie  zombie apocalypse  \\\n",
       "0                 13  ...     0.0         0.0     0.0                0.0   \n",
       "1                  7  ...     0.0         0.0     0.0                0.0   \n",
       "2                 20  ...     0.0         0.0     0.0                0.0   \n",
       "3                  8  ...     0.0         0.0     0.0                0.0   \n",
       "4                 15  ...     0.0         0.0     0.0                0.0   \n",
       "\n",
       "   zone  zone coming  zone dont  zouma  zouma flattened  _target_  \n",
       "0   0.0          0.0        0.0    0.0              0.0         1  \n",
       "1   0.0          0.0        0.0    0.0              0.0         1  \n",
       "2   0.0          0.0        0.0    0.0              0.0         1  \n",
       "3   0.0          0.0        0.0    0.0              0.0         1  \n",
       "4   0.0          0.0        0.0    0.0              0.0         1  \n",
       "\n",
       "[5 rows x 10932 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinamos TFIDF con los features obtenidos (TRAIN SET)\n",
    "train_data = train_data.reset_index()\n",
    "train_data = train_data.merge(df_tf_idf, how='inner',on='index')\n",
    "train_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id_x</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location_x</th>\n",
       "      <th>text_x</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tagged_text</th>\n",
       "      <th>tagged_clean_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>zippednews</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipper bag</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombie apocalypse</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone coming</th>\n",
       "      <th>zone dont</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zouma flattened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>[(Just, RB), (happened, VBD), (a, DT), (terrib...</td>\n",
       "      <td>[(happened, VBN), (terrible, JJ), (car, NN), (...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td>[(Heard, NNP), (about, IN), (#, #), (earthquak...</td>\n",
       "      <td>[(heard, RB), (earthquake, NN), (different, JJ...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td>[(there, EX), (is, VBZ), (a, DT), (forest, JJ)...</td>\n",
       "      <td>[(forest, JJS), (fire, NN), (spot, NN), (pond,...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[(Apocalypse, NNP), (lighting, NN), (., .), (#...</td>\n",
       "      <td>[(apocalypse, NN), (lighting, VBG), (spokane, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>no keyword</td>\n",
       "      <td>no location</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[(Typhoon, NNP), (Soudelor, NNP), (kills, VBZ)...</td>\n",
       "      <td>[(typhoon, NN), (soudelor, NN), (kill, VB), (c...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 10931 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  id_x     keyword   location_x  \\\n",
       "0      0     0  no keyword  no location   \n",
       "1      1     2  no keyword  no location   \n",
       "2      2     3  no keyword  no location   \n",
       "3      3     9  no keyword  no location   \n",
       "4      4    11  no keyword  no location   \n",
       "\n",
       "                                              text_x  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Heard about #earthquake is different cities, s...   \n",
       "2  there is a forest fire at spot pond, geese are...   \n",
       "3           Apocalypse lighting. #Spokane #wildfires   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                        happened terrible car crash   \n",
       "1  heard earthquake different city stay safe ever...   \n",
       "2  forest fire spot pond goose fleeing across str...   \n",
       "3               apocalypse lighting spokane wildfire   \n",
       "4                 typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                         tagged_text  \\\n",
       "0  [(Just, RB), (happened, VBD), (a, DT), (terrib...   \n",
       "1  [(Heard, NNP), (about, IN), (#, #), (earthquak...   \n",
       "2  [(there, EX), (is, VBZ), (a, DT), (forest, JJ)...   \n",
       "3  [(Apocalypse, NNP), (lighting, NN), (., .), (#...   \n",
       "4  [(Typhoon, NNP), (Soudelor, NNP), (kills, VBZ)...   \n",
       "\n",
       "                                   tagged_clean_text  word_count  \\\n",
       "0  [(happened, VBN), (terrible, JJ), (car, NN), (...           6   \n",
       "1  [(heard, RB), (earthquake, NN), (different, JJ...           9   \n",
       "2  [(forest, JJS), (fire, NN), (spot, NN), (pond,...          19   \n",
       "3  [(apocalypse, NN), (lighting, VBG), (spokane, ...           4   \n",
       "4  [(typhoon, NN), (soudelor, NN), (kill, VB), (c...           8   \n",
       "\n",
       "   unique_word_count  ...  zippednews  zipper  zipper bag  zombie  \\\n",
       "0                  6  ...         0.0     0.0         0.0     0.0   \n",
       "1                  9  ...         0.0     0.0         0.0     0.0   \n",
       "2                 19  ...         0.0     0.0         0.0     0.0   \n",
       "3                  4  ...         0.0     0.0         0.0     0.0   \n",
       "4                  8  ...         0.0     0.0         0.0     0.0   \n",
       "\n",
       "   zombie apocalypse  zone  zone coming  zone dont  zouma  zouma flattened  \n",
       "0                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "1                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "2                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "3                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "4                0.0   0.0          0.0        0.0    0.0              0.0  \n",
       "\n",
       "[5 rows x 10931 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combinamos TFIDF con los features obtenidos (TEST SET)\n",
    "test_data = test_data.reset_index()  \n",
    "test_data = test_data.merge(df_tf_idf_test, how='inner',on='index')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construimos los datos de entrenamiento y de test\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = train_data.drop([\"_target_\",'tagged_text','tagged_clean_text','index','clean_text','text_x','target_x','keyword','location_x'], axis=1)\n",
    "X = X.values\n",
    "y = train_data[\"_target_\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Preparamos los datos de Test\n",
    "X_TEST = test_data.drop(['id_x','tagged_text','tagged_clean_text','index','clean_text','text_x','keyword','location_x'], axis=1)\n",
    "X_TEST = scaler.fit_transform(X_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "#Luego de consultar con mi equipo de los random search realizados, declaro el modelo con los hiperparametros siguientes\n",
    "clf = xgb.XGBClassifier(max_depth=200, n_estimators=400, subsample=1, learning_rate=0.07, reg_lambda=0.1, reg_alpha=0.1,\\\n",
    "                       gamma=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1score = f1_score(y_test, predictions)\n",
    "print(f'Counts model score: {f1score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparamos el submit\n",
    "\n",
    "predictions = clf.predict(X_TEST)\n",
    "\n",
    "test_data['id'] = test_data['id_x']\n",
    "test_data['target'] = predictions.astype(int)\n",
    "submission = test_data.loc[:,['id','target']]\n",
    "submission.to_csv(path_or_buf='submissionTFIDF-xgb.csv',header=True,index=False)\n",
    "len(submission)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observamos la distribuci√≥n de las predicciones \n",
    "submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
