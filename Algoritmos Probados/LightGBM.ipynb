{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('train.csv')\n",
    "tweets_test = pd.read_csv('test.csv')\n",
    "\n",
    "tweets['len_text']=tweets['text'].str.len()\n",
    "tweets_test['len_text']=tweets_test['text'].str.len()\n",
    "\n",
    "tweets['keyword'] = tweets['keyword'].str.replace('%20', ' ')\n",
    "tweets['keyword'].fillna('no keyword', inplace = True)\n",
    "\n",
    "tweets_test['keyword'] = tweets_test['keyword'].str.replace('%20', ' ')\n",
    "tweets_test['keyword'].fillna('no keyword', inplace = True)\n",
    "\n",
    "tweets = tweets.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['text'].str.lower()\n",
    "tweets_test['clean_text'] = tweets_test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_letters(tweet):\n",
    "    tweet = re.sub(r'http\\S*', '', tweet)\n",
    "    tweet = re.sub(r'[^a-z\\s]', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(only_letters)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(only_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenización\n",
    "from nltk.tokenize import word_tokenize\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(word_tokenize)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(word_tokenize)\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(tokenized_text):\n",
    "    not_stopwords=[]\n",
    "    for w in tokenized_text:\n",
    "        if w not in stop_words:\n",
    "            not_stopwords.append(w)\n",
    "    return not_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(filter_stopwords)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(filter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweet):\n",
    "    lemmatized_words = []\n",
    "    for word in tweet:\n",
    "        lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(lemmatize_tweet)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lemmatize_tweet)\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda text:' '.join(text))\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lambda text:' '.join(text))\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda text: re.sub(r'amp | im', '', text))\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lambda text: re.sub(r'amp | im', '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nuevos features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hashtags del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtags(s):\n",
    "    return list(part[1:] for part in s.split() if part.startswith('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['hashtags'] = tweets['text'].apply(get_hashtags)\n",
    "tweets_test['hashtags'] = tweets_test['text'].apply(get_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proporción de la longitud del hashtag con respecto a la del texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_length_proportion(hashtags,length):\n",
    "    return len(''.join(hashtags))/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['len_hashtag_over_text'] = tweets.apply(lambda data: hashtag_length_proportion(data['hashtags'],data['len_text']),axis=1)\n",
    "tweets_test['len_hashtag_over_text'] = tweets_test.apply(lambda data: hashtag_length_proportion(data['hashtags'],data['len_text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cantidad de hashtags del tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtags_count(l):\n",
    "    return len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['hashtags_count']=tweets['hashtags'].apply(hashtags_count)\n",
    "tweets_test['hashtags_count']=tweets_test['hashtags'].apply(hashtags_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usuarios mencionados en el tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mentioned_users(s):\n",
    "    return list(part[1:] for part in s.split() if part.startswith('@'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['users'] = tweets['text'].apply(get_mentioned_users)\n",
    "tweets_test['users'] = tweets_test['text'].apply(get_mentioned_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def users_count(l):\n",
    "    return len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['users_count']=tweets['users'].apply(users_count)\n",
    "tweets_test['users_count']=tweets_test['users'].apply(users_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls en el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(text):\n",
    "    urls = re.findall(r'(https?://\\S+)', text)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['urls']=tweets['text'].apply(find_url)\n",
    "tweets_test['urls']=tweets_test['text'].apply(find_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_count(l):\n",
    "    return len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['urls_count'] = tweets['urls'].apply(lambda x: len(x))\n",
    "tweets_test['urls_count'] = tweets_test['urls'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_url(text):\n",
    "    return int('http' in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['has_url']=tweets['text'].apply(has_url)\n",
    "tweets_test['has_url']=tweets_test['text'].apply(has_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean encoding keyword\n",
    "tweets['keyword_encoded'] = tweets.groupby('keyword')['target'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict = pd.Series(tweets['keyword_encoded'].values, index=tweets['keyword']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['keyword_encoded']= tweets_test['keyword'].map(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['len_clean_text'] = tweets['clean_text'].str.len()\n",
    "tweets_test['len_clean_text'] = tweets_test['clean_text'].str.len()\n",
    "\n",
    "#Proporción de longitud de clean_text con respecto texto original\n",
    "tweets['len_clean_text_over_text'] = tweets['len_clean_text']/tweets['len_text']\n",
    "tweets_test['len_clean_text_over_text'] = tweets_test['len_clean_text']/tweets_test['len_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>len_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>len_hashtag_over_text</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>users</th>\n",
       "      <th>users_count</th>\n",
       "      <th>urls</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>keyword_encoded</th>\n",
       "      <th>len_clean_text</th>\n",
       "      <th>len_clean_text_over_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>4632</td>\n",
       "      <td>emergency services</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>Goulburn man Henry Van Bilsen missing: Emergen...</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>goulburn man henry van bilsen missing emergenc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[http://t.co/z99pKJzTRp]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>90</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>5271</td>\n",
       "      <td>fear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The things we fear most in organizations--fluc...</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>thing fear organizationsfluctuations disturban...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>103</td>\n",
       "      <td>0.746377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>9982</td>\n",
       "      <td>tsunami</td>\n",
       "      <td>Land Of The Kings</td>\n",
       "      <td>@tsunami_esh ?? hey Esh</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>tsunamiesh hey esh</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[tsunami_esh]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>18</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>4149</td>\n",
       "      <td>drown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@POTUS you until you drown by water entering t...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>potus drown water entering lung alive caused g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[POTUS]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>80</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>10680</td>\n",
       "      <td>wounds</td>\n",
       "      <td>cody, austin follows ?*?</td>\n",
       "      <td>Crawling in my skin\\r\\nThese wounds they will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>crawling skin wound hea</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>23</td>\n",
       "      <td>0.450980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             keyword                  location  \\\n",
       "3228   4632  emergency services   Sydney, New South Wales   \n",
       "3706   5271                fear                       NaN   \n",
       "6957   9982             tsunami         Land Of The Kings   \n",
       "2887   4149               drown                       NaN   \n",
       "7464  10680              wounds  cody, austin follows ?*?   \n",
       "\n",
       "                                                   text  target  len_text  \\\n",
       "3228  Goulburn man Henry Van Bilsen missing: Emergen...       1       141   \n",
       "3706  The things we fear most in organizations--fluc...       0       138   \n",
       "6957                            @tsunami_esh ?? hey Esh       0        23   \n",
       "2887  @POTUS you until you drown by water entering t...       0       140   \n",
       "7464  Crawling in my skin\\r\\nThese wounds they will ...       1        51   \n",
       "\n",
       "                                             clean_text hashtags  \\\n",
       "3228  goulburn man henry van bilsen missing emergenc...       []   \n",
       "3706  thing fear organizationsfluctuations disturban...       []   \n",
       "6957                                 tsunamiesh hey esh       []   \n",
       "2887  potus drown water entering lung alive caused g...       []   \n",
       "7464                            crawling skin wound hea       []   \n",
       "\n",
       "      len_hashtag_over_text  hashtags_count          users  users_count  \\\n",
       "3228                    0.0               0             []            0   \n",
       "3706                    0.0               0             []            0   \n",
       "6957                    0.0               0  [tsunami_esh]            1   \n",
       "2887                    0.0               0        [POTUS]            1   \n",
       "7464                    0.0               0             []            0   \n",
       "\n",
       "                          urls  urls_count  has_url  keyword_encoded  \\\n",
       "3228  [http://t.co/z99pKJzTRp]           1        1         0.333333   \n",
       "3706                        []           0        0         0.125000   \n",
       "6957                        []           0        0         0.323529   \n",
       "2887                        []           0        0         0.093750   \n",
       "7464                        []           0        0         0.303030   \n",
       "\n",
       "      len_clean_text  len_clean_text_over_text  \n",
       "3228              90                  0.638298  \n",
       "3706             103                  0.746377  \n",
       "6957              18                  0.782609  \n",
       "2887              80                  0.571429  \n",
       "7464              23                  0.450980  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_hashtag_over_text</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>users_count</th>\n",
       "      <th>keyword_encoded</th>\n",
       "      <th>len_clean_text</th>\n",
       "      <th>len_clean_text_over_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>90</td>\n",
       "      <td>0.638298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>103</td>\n",
       "      <td>0.746377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>18</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>80</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>23</td>\n",
       "      <td>0.450980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      len_text  len_hashtag_over_text  hashtags_count  has_url  urls_count  \\\n",
       "3228       141                    0.0               0        1           1   \n",
       "3706       138                    0.0               0        0           0   \n",
       "6957        23                    0.0               0        0           0   \n",
       "2887       140                    0.0               0        0           0   \n",
       "7464        51                    0.0               0        0           0   \n",
       "\n",
       "      users_count  keyword_encoded  len_clean_text  len_clean_text_over_text  \n",
       "3228            0         0.333333              90                  0.638298  \n",
       "3706            0         0.125000             103                  0.746377  \n",
       "6957            1         0.323529              18                  0.782609  \n",
       "2887            1         0.093750              80                  0.571429  \n",
       "7464            0         0.303030              23                  0.450980  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Me quedo con las columnas numéricas\n",
    "df = tweets.loc[:,['len_text','len_hashtag_over_text','hashtags_count','has_url','urls_count','users_count','keyword_encoded','len_clean_text','len_clean_text_over_text']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_text</th>\n",
       "      <th>len_hashtag_over_text</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>has_url</th>\n",
       "      <th>urls_count</th>\n",
       "      <th>users_count</th>\n",
       "      <th>keyword_encoded</th>\n",
       "      <th>len_clean_text</th>\n",
       "      <th>len_clean_text_over_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>27</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>50</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>54</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>36</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>34</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   len_text  len_hashtag_over_text  hashtags_count  has_url  urls_count  \\\n",
       "0        34                0.00000               0        0           0   \n",
       "1        64                0.15625               1        0           0   \n",
       "2        96                0.00000               0        0           0   \n",
       "3        40                0.40000               2        0           0   \n",
       "4        45                0.00000               0        0           0   \n",
       "\n",
       "   users_count  keyword_encoded  len_clean_text  len_clean_text_over_text  \n",
       "0            0         0.688525              27                  0.794118  \n",
       "1            0         0.688525              50                  0.781250  \n",
       "2            0         0.688525              54                  0.562500  \n",
       "3            0         0.688525              36                  0.900000  \n",
       "4            0         0.688525              34                  0.755556  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = tweets_test.loc[:,['len_text','len_hashtag_over_text','hashtags_count','has_url','urls_count','users_count','keyword_encoded','len_clean_text','len_clean_text_over_text']]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tweets['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    " \"num_leaves\"    : [40, 50, 60] ,\n",
    " \"min_data_in_leaf\" : [ 3, 4, 5, 6],\n",
    " \"max_depth\" : [ 3,4,5],\n",
    " \"learning_rate\": [ 0.1, 0.15, 0.2],\n",
    " \"num_iterations\" : [ 90, 100, 110, 120],\n",
    " \"feature_fraction\" : [0.4, 0.5, 0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(model,param_distributions=params,scoring='f1',cv=5,verbose=1,n_iter=1400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.fit(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicciones set de train\n",
    "preds = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = f1_score(tweets['target'], preds)\n",
    "print(f'Counts model score: {f1score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(tweets['target'], preds))\n",
    "print(f'RMSE: %f' % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(tweets['target'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicciones set de test\n",
    "preds_test = model.predict(df_test)\n",
    "preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['target'] = preds_test.astype(int)\n",
    "submission = tweets_test.loc[:,['id','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf='submissionlgbm.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "plot_importance(model, max_num_features=10, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle\n",
    "#pickle.dump(model, open(\"modelolgbm\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
