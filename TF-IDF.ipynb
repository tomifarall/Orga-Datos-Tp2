{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('train.csv')\n",
    "tweets['length']=tweets['text'].str.len()\n",
    "tweets['keyword'] = tweets['keyword'].str.replace('%20', ' ')\n",
    "tweets['keyword'].fillna('no keyword', inplace = True)\n",
    "tweets = tweets.sample(frac=1,random_state=1)\n",
    "tweets_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['text'].str.lower()\n",
    "tweets_test['clean_text'] = tweets_test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_letters(tweet):\n",
    "    tweet = re.sub(r'http\\S*', '', tweet)\n",
    "    tweet = re.sub(r'[^a-z\\s]', '', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(only_letters)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(only_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenización\n",
    "from nltk.tokenize import word_tokenize\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(word_tokenize)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(word_tokenize)\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(tokenized_text):\n",
    "    not_stopwords=[]\n",
    "    for w in tokenized_text:\n",
    "        if w not in stop_words:\n",
    "            not_stopwords.append(w)\n",
    "    return not_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(filter_stopwords)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(filter_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lematización\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tweet(tweet):\n",
    "    lemmatized_words = []\n",
    "    for word in tweet:\n",
    "        lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['clean_text'] = tweets['clean_text'].apply(lemmatize_tweet)\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lemmatize_tweet)\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda text:' '.join(text))\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lambda text:' '.join(text))\n",
    "tweets['clean_text'] = tweets['clean_text'].apply(lambda text: re.sub(r'amp | im', '', text))\n",
    "tweets_test['clean_text'] = tweets_test['clean_text'].apply(lambda text: re.sub(r'amp | im', '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3228</th>\n",
       "      <td>4632</td>\n",
       "      <td>emergency services</td>\n",
       "      <td>Sydney, New South Wales</td>\n",
       "      <td>Goulburn man Henry Van Bilsen missing: Emergen...</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>goulburn man henry van bilsen missing emergenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3706</th>\n",
       "      <td>5271</td>\n",
       "      <td>fear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The things we fear most in organizations--fluc...</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>thing fear organizationsfluctuations disturban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>9982</td>\n",
       "      <td>tsunami</td>\n",
       "      <td>Land Of The Kings</td>\n",
       "      <td>@tsunami_esh ?? hey Esh</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>tsunamiesh hey esh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>4149</td>\n",
       "      <td>drown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@POTUS you until you drown by water entering t...</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>potus drown water entering lung alive caused g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7464</th>\n",
       "      <td>10680</td>\n",
       "      <td>wounds</td>\n",
       "      <td>cody, austin follows ?*?</td>\n",
       "      <td>Crawling in my skin\\r\\nThese wounds they will ...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>crawling skin wound hea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             keyword                  location  \\\n",
       "3228   4632  emergency services   Sydney, New South Wales   \n",
       "3706   5271                fear                       NaN   \n",
       "6957   9982             tsunami         Land Of The Kings   \n",
       "2887   4149               drown                       NaN   \n",
       "7464  10680              wounds  cody, austin follows ?*?   \n",
       "\n",
       "                                                   text  target  length  \\\n",
       "3228  Goulburn man Henry Van Bilsen missing: Emergen...       1     141   \n",
       "3706  The things we fear most in organizations--fluc...       0     138   \n",
       "6957                            @tsunami_esh ?? hey Esh       0      23   \n",
       "2887  @POTUS you until you drown by water entering t...       0     140   \n",
       "7464  Crawling in my skin\\r\\nThese wounds they will ...       1      51   \n",
       "\n",
       "                                             clean_text  \n",
       "3228  goulburn man henry van bilsen missing emergenc...  \n",
       "3706  thing fear organizationsfluctuations disturban...  \n",
       "6957                                 tsunamiesh hey esh  \n",
       "2887  potus drown water entering lung alive caused g...  \n",
       "7464                            crawling skin wound hea  "
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(ngram_range=(1,1),min_df=2)\n",
    "train_tfidf=tfidf_vectorizer.fit_transform(tweets['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_tfidf\n",
    "y = tweets['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76837945 0.76198083 0.74841772 0.76183088 0.76062992]\n"
     ]
    }
   ],
   "source": [
    "model=LogisticRegression(class_weight='balanced')\n",
    "print(cross_val_score(model, X, y, cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts model score: 76.02523659305994%\n"
     ]
    }
   ],
   "source": [
    "#Set train\n",
    "y_pred_log = cross_val_predict(model, X, y, cv=5)\n",
    "f1score = f1_score(tweets['target'], y_pred_log)\n",
    "print(f'Counts model score: {f1score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3683</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>861</td>\n",
       "      <td>2410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0     1\n",
       "target            \n",
       "0       3683   659\n",
       "1        861  2410"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tweets['target'],y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3683  659]\n",
      " [ 861 2410]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(tweets['target'], y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regressor\n",
    "y_pred_log_probabilities = cross_val_predict(model, X, y, cv=5, method='predict_proba')\n",
    "y_pred_log_probabilities = np.array(y_pred_log_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log_prob = y_pred_log_probabilities[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train_log_prob.csv\", pd.DataFrame(y_train_log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set test\n",
    "model.fit(X, y)\n",
    "test_predictions = model.predict(tfidf_vectorizer.transform(tweets_test['clean_text']))\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_test['target'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different city stay safe ever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond goose fleeing across str...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're shaking...It's an earthquake</td>\n",
       "      <td>shakingits earthquake</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They'd probably still show more life than Arse...</td>\n",
       "      <td>theyd probably still show life arsenal yesterd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hey! How are you?</td>\n",
       "      <td>hey</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What a nice hat?</td>\n",
       "      <td>nice hat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fuck off!</td>\n",
       "      <td>fuck</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No I don't like cold!</td>\n",
       "      <td>dont like cold</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOOOOOOOOO! Don't do that!</td>\n",
       "      <td>nooooooooo dont</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No don't tell me that!</td>\n",
       "      <td>dont tell</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What if?!</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>awesome</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "      <td>birmingham wholesale market ablaze bbc news fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "      <td>sunkxssedharry wear short race ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "      <td>previouslyondoyintv toke makinwas marriage cri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>check nsfw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\r\\n\\r\\n...</td>\n",
       "      <td>psa im splitting personality techie follow abl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                        location  \\\n",
       "0    0     NaN                             NaN   \n",
       "1    2     NaN                             NaN   \n",
       "2    3     NaN                             NaN   \n",
       "3    9     NaN                             NaN   \n",
       "4   11     NaN                             NaN   \n",
       "5   12     NaN                             NaN   \n",
       "6   21     NaN                             NaN   \n",
       "7   22     NaN                             NaN   \n",
       "8   27     NaN                             NaN   \n",
       "9   29     NaN                             NaN   \n",
       "10  30     NaN                             NaN   \n",
       "11  35     NaN                             NaN   \n",
       "12  42     NaN                             NaN   \n",
       "13  43     NaN                             NaN   \n",
       "14  45     NaN                             NaN   \n",
       "15  46  ablaze                          London   \n",
       "16  47  ablaze  Niall's place | SAF 12 SQUAD |   \n",
       "17  51  ablaze                         NIGERIA   \n",
       "18  58  ablaze                  Live On Webcam   \n",
       "19  60  ablaze        Los Angeles, Califnordia   \n",
       "\n",
       "                                                 text  \\\n",
       "0                  Just happened a terrible car crash   \n",
       "1   Heard about #earthquake is different cities, s...   \n",
       "2   there is a forest fire at spot pond, geese are...   \n",
       "3            Apocalypse lighting. #Spokane #wildfires   \n",
       "4       Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "5                  We're shaking...It's an earthquake   \n",
       "6   They'd probably still show more life than Arse...   \n",
       "7                                   Hey! How are you?   \n",
       "8                                    What a nice hat?   \n",
       "9                                           Fuck off!   \n",
       "10                              No I don't like cold!   \n",
       "11                         NOOOOOOOOO! Don't do that!   \n",
       "12                             No don't tell me that!   \n",
       "13                                          What if?!   \n",
       "14                                           Awesome!   \n",
       "15  Birmingham Wholesale Market is ablaze BBC News...   \n",
       "16  @sunkxssedharry will you wear shorts for race ...   \n",
       "17  #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...   \n",
       "18  Check these out: http://t.co/rOI2NSmEJJ http:/...   \n",
       "19  PSA: IÛªm splitting my personalities.\\r\\n\\r\\n...   \n",
       "\n",
       "                                           clean_text  target  \n",
       "0                         happened terrible car crash       1  \n",
       "1   heard earthquake different city stay safe ever...       1  \n",
       "2   forest fire spot pond goose fleeing across str...       1  \n",
       "3                apocalypse lighting spokane wildfire       1  \n",
       "4                  typhoon soudelor kill china taiwan       1  \n",
       "5                               shakingits earthquake       1  \n",
       "6   theyd probably still show life arsenal yesterd...       0  \n",
       "7                                                 hey       0  \n",
       "8                                            nice hat       0  \n",
       "9                                                fuck       0  \n",
       "10                                     dont like cold       0  \n",
       "11                                    nooooooooo dont       0  \n",
       "12                                          dont tell       0  \n",
       "13                                                          0  \n",
       "14                                            awesome       0  \n",
       "15  birmingham wholesale market ablaze bbc news fi...       1  \n",
       "16              sunkxssedharry wear short race ablaze       0  \n",
       "17  previouslyondoyintv toke makinwas marriage cri...       1  \n",
       "18                                         check nsfw       0  \n",
       "19  psa im splitting personality techie follow abl...       0  "
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  target\n",
       "0    0       1\n",
       "1    2       1\n",
       "2    3       1\n",
       "3    9       1\n",
       "4   11       1\n",
       "5   12       1\n",
       "6   21       0\n",
       "7   22       0\n",
       "8   27       0\n",
       "9   29       0\n",
       "10  30       0\n",
       "11  35       0\n",
       "12  42       0\n",
       "13  43       0\n",
       "14  45       0\n",
       "15  46       1\n",
       "16  47       0\n",
       "17  51       1\n",
       "18  58       0\n",
       "19  60       0"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = tweets_test.loc[:,['id','target']]\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf='submission.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(list(y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21177565, 0.78822435],\n",
       "       [0.3256102 , 0.6743898 ],\n",
       "       [0.19248937, 0.80751063],\n",
       "       ...,\n",
       "       [0.22083745, 0.77916255],\n",
       "       [0.25862416, 0.74137584],\n",
       "       [0.44719953, 0.55280047]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict_proba(tfidf_vectorizer.transform(tweets_test['clean_text']))\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_log_prob = test_predictions[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78822435, 0.6743898 , 0.80751063, ..., 0.77916255, 0.74137584,\n",
       "       0.55280047])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test_log_prob.csv\", pd.DataFrame(y_test_log_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perceptrón**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68527132 0.69300912 0.69923664 0.69327421 0.69353612]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "model=Perceptron(tol=1e-3, random_state=0)\n",
    "print(cross_val_score(model, X, y, cv=5,scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts model score: 69.41643751909564%\n"
     ]
    }
   ],
   "source": [
    "y_pred_per=cross_val_predict(model, X, y, cv=10)\n",
    "f1score = f1_score(tweets['target'], y_pred_per)\n",
    "print(f'Counts model score: {f1score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3339</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>2272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      0     1\n",
       "target            \n",
       "0       3339  1003\n",
       "1        999  2272"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tweets['target'],y_pred_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión lineal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -26.39675499  -45.62558326  -37.26173536  -21.75104382 -104.5037961 ]\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(model, X, y, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lin=cross_val_predict(model, X, y, cv=5)\n",
    "np.savetxt(\"train_lin.csv\", pd.DataFrame(y_pred_lin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts model score: 57.326846021751564%\n"
     ]
    }
   ],
   "source": [
    "y_pred_lin = y_pred_lin >=0.5\n",
    "        \n",
    "f1score = f1_score(tweets['target'], y_pred_lin)\n",
    "print(f'Counts model score: {f1score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2628</td>\n",
       "      <td>1714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0   False  True \n",
       "target              \n",
       "0        2628   1714\n",
       "1        1268   2003"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tweets['target'],y_pred_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lin_predictions = model.predict(tfidf_vectorizer.transform(tweets_test['clean_text']))\n",
    "#list(test_lin_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lin_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.789428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.575369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.568077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.833260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>0.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>1.126309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.052035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>0.146149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.246498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>-0.288499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  lin_pred\n",
       "0   0  0.789428\n",
       "1   2  0.575369\n",
       "2   3  0.568077\n",
       "3   9  0.833260\n",
       "4  11  0.642000\n",
       "5  12  1.126309\n",
       "6  21 -0.052035\n",
       "7  22  0.146149\n",
       "8  27 -0.246498\n",
       "9  29 -0.288499"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test['lin_pred'] = test_lin_predictions\n",
    "submission = tweets_test.loc[:,['id','lin_pred']]\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path_or_buf='lin_pred.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Promediando resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True, False, False])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p = (y_pred_log + y_pred_per + y_pred_lin)/3\n",
    "y_p = y_p >=0.5\n",
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts model score: 72.2127196392474%\n"
     ]
    }
   ],
   "source": [
    "f1score = f1_score(tweets['target'], y_p)\n",
    "print(f'Counts model score: {f1score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no sirve, es mejor la regresión logística sola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
